{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the notebook used for training the model.\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define paths to the dataset\n",
    "BASE_PATH = '/kaggle/input/soil-classification-part-2/soil_competition-2025/'\n",
    "TRAIN_PATH = BASE_PATH + 'train/'\n",
    "TRAIN_LABELS = BASE_PATH + 'train_labels.csv'\n",
    "\n",
    "# Load the training dataset\n",
    "train_labels = pd.read_csv(TRAIN_LABELS)\n",
    "train_labels['image_path'] = train_labels['image_id'].apply(lambda x: os.path.join(TRAIN_PATH, x))\n",
    "\n",
    "print(f\"Training dataset shape: {train_labels.shape}\")\n",
    "print(f\"Sample image paths: {train_labels['image_path'].head()}\")\n",
    "\n",
    "# Step 1: Feature Extraction using Pre-trained EfficientNetB0\n",
    "def create_feature_extractor():\n",
    "    \"\"\"Create a feature extractor using EfficientNetB0 pre-trained on ImageNet.\"\"\"\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess an image for feature extraction.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return np.zeros((224, 224, 3))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "# Data augmentation for training images\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Load and preprocess training images\n",
    "print(\"Loading training images...\")\n",
    "train_images = np.array([load_and_preprocess_image(path) for path in train_labels['image_path']])\n",
    "print(f\"Training images shape: {train_images.shape}\")\n",
    "\n",
    "# Apply augmentation to training images\n",
    "print(\"Applying data augmentation...\")\n",
    "augmented_images = []\n",
    "for i, img in enumerate(train_images):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Augmenting image {i}/{len(train_images)}\")\n",
    "    img = img.reshape((1,) + img.shape)  # Reshape for ImageDataGenerator\n",
    "    for batch in datagen.flow(img, batch_size=1):\n",
    "        augmented_images.append(batch[0])\n",
    "        break  # Take only one augmented image per original\n",
    "augmented_images = np.array(augmented_images)\n",
    "\n",
    "# Combine original and augmented images\n",
    "all_train_images = np.concatenate([train_images, augmented_images], axis=0)\n",
    "print(f\"Total training images after augmentation: {all_train_images.shape}\")\n",
    "\n",
    "# Extract features using EfficientNetB0\n",
    "print(\"Creating feature extractor...\")\n",
    "feature_extractor = create_feature_extractor()\n",
    "\n",
    "print(\"Extracting training features...\")\n",
    "all_train_features = feature_extractor.predict(all_train_images, batch_size=32, verbose=1)\n",
    "print(f\"Training features shape: {all_train_features.shape}\")\n",
    "\n",
    "# Split into train and validation sets (80-20 split)\n",
    "val_size = int(0.2 * len(all_train_features))\n",
    "train_features = all_train_features[:-val_size]\n",
    "val_features = all_train_features[-val_size:]\n",
    "\n",
    "print(f\"Training features shape: {train_features.shape}\")\n",
    "print(f\"Validation features shape: {val_features.shape}\")\n",
    "\n",
    "# Step 2: Autoencoder for Anomaly Detection\n",
    "def create_autoencoder(input_dim):\n",
    "    \"\"\"Create a lightweight autoencoder for anomaly detection.\"\"\"\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(64, activation='relu')(input_layer)\n",
    "    decoded = Dense(input_dim, activation='linear')(encoded)\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "# Train the autoencoder\n",
    "print(\"Training autoencoder...\")\n",
    "autoencoder = create_autoencoder(train_features.shape[1])\n",
    "\n",
    "# Display model architecture\n",
    "print(\"Autoencoder Architecture:\")\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(\n",
    "    train_features, train_features,\n",
    "    epochs=30,  # Reduced epochs for faster training\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Autoencoder Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss (Log Scale)')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss (Log Scale)')\n",
    "plt.title('Autoencoder Training Loss (Log Scale)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the trained models\n",
    "print(\"Saving trained models...\")\n",
    "feature_extractor.save('feature_extractor_model.h5')\n",
    "autoencoder.save('autoencoder_model.h5')\n",
    "\n",
    "# Save features for inference\n",
    "np.save('train_features.npy', train_features)\n",
    "np.save('val_features.npy', val_features)\n",
    "\n",
    "print(\"Training completed successfully!\")\n",
    "print(\"Saved files:\")\n",
    "print(\"- feature_extractor_model.h5\")\n",
    "print(\"- autoencoder_model.h5\") \n",
    "print(\"- train_features.npy\")\n",
    "print(\"- val_features.npy\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
