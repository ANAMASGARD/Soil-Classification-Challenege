{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the notebook used for making the inferences using the model trained.\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define paths to the dataset\n",
    "BASE_PATH = '/kaggle/input/soil-classification-part-2/soil_competition-2025/'\n",
    "TEST_PATH = BASE_PATH + 'test/'\n",
    "TEST_IDS = BASE_PATH + 'test_ids.csv'\n",
    "\n",
    "# Load test dataset\n",
    "test_ids = pd.read_csv(TEST_IDS)\n",
    "test_ids['image_path'] = test_ids['image_id'].apply(lambda x: os.path.join(TEST_PATH, x))\n",
    "\n",
    "print(f\"Test dataset shape: {test_ids.shape}\")\n",
    "print(f\"Sample test image paths: {test_ids['image_path'].head()}\")\n",
    "\n",
    "# Load pre-trained models\n",
    "print(\"Loading pre-trained models...\")\n",
    "feature_extractor = load_model('feature_extractor_model.h5')\n",
    "autoencoder = load_model('autoencoder_model.h5')\n",
    "\n",
    "# Load training features for threshold computation\n",
    "train_features = np.load('train_features.npy')\n",
    "val_features = np.load('val_features.npy')\n",
    "\n",
    "print(\"Models loaded successfully!\")\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess an image for feature extraction.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return np.zeros((224, 224, 3))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "# Load and preprocess test images\n",
    "print(\"Loading test images...\")\n",
    "test_images = np.array([load_and_preprocess_image(path) for path in test_ids['image_path']])\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "\n",
    "# Extract test features\n",
    "print(\"Extracting test features...\")\n",
    "test_features = feature_extractor.predict(test_images, batch_size=32, verbose=1)\n",
    "print(f\"Test features shape: {test_features.shape}\")\n",
    "\n",
    "# Compute reconstruction errors\n",
    "print(\"Computing reconstruction errors...\")\n",
    "train_recon = autoencoder.predict(train_features, batch_size=32, verbose=1)\n",
    "train_errors = np.mean(np.square(train_features - train_recon), axis=1)\n",
    "\n",
    "val_recon = autoencoder.predict(val_features, batch_size=32, verbose=1)\n",
    "val_errors = np.mean(np.square(val_features - val_recon), axis=1)\n",
    "\n",
    "test_recon = autoencoder.predict(test_features, batch_size=32, verbose=1)\n",
    "test_errors = np.mean(np.square(test_features - test_recon), axis=1)\n",
    "\n",
    "print(f\"Training reconstruction errors - Mean: {np.mean(train_errors):.6f}, Std: {np.std(train_errors):.6f}\")\n",
    "print(f\"Validation reconstruction errors - Mean: {np.mean(val_errors):.6f}, Std: {np.std(val_errors):.6f}\")\n",
    "print(f\"Test reconstruction errors - Mean: {np.mean(test_errors):.6f}, Std: {np.std(test_errors):.6f}\")\n",
    "\n",
    "# Step 3: Dynamic Threshold Selection\n",
    "# Simulate non-soil images in validation set by taking high-error samples\n",
    "val_pseudo_labels = np.ones(len(val_errors))  # Start with all as soil (1)\n",
    "error_threshold_for_pseudo = np.percentile(val_errors, 90)  # Top 10% errors as pseudo non-soil\n",
    "val_pseudo_labels[val_errors > error_threshold_for_pseudo] = 0  # Label high errors as non-soil\n",
    "\n",
    "print(f\"Validation pseudo-labeling threshold: {error_threshold_for_pseudo:.6f}\")\n",
    "print(f\"Pseudo soil labels: {np.sum(val_pseudo_labels)} ({np.mean(val_pseudo_labels)*100:.1f}%)\")\n",
    "print(f\"Pseudo non-soil labels: {len(val_pseudo_labels) - np.sum(val_pseudo_labels)} ({(1 - np.mean(val_pseudo_labels))*100:.1f}%)\")\n",
    "\n",
    "# Test multiple thresholds and pick the best based on F1-score\n",
    "thresholds = [np.percentile(train_errors, p) for p in [50, 75, 90]]\n",
    "best_threshold = None\n",
    "best_f1 = 0\n",
    "\n",
    "print(\"Selecting best threshold based on validation F1-score...\")\n",
    "print(\"Threshold\\tF1-Score\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    val_preds = np.where(val_errors <= threshold, 1, 0)\n",
    "    f1 = f1_score(val_pseudo_labels, val_preds)\n",
    "    print(f\"{threshold:.6f}\\t{f1:.4f}\")\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest threshold: {best_threshold:.6f} with F1-score: {best_f1:.4f}\")\n",
    "\n",
    "# Apply the best threshold to test predictions\n",
    "test_preds = np.where(test_errors <= best_threshold, 1, 0)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'image_id': test_ids['image_id'],\n",
    "    'label': test_preds\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created: submission.csv\")\n",
    "\n",
    "# Display prediction statistics\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(f\"Soil predictions: {np.sum(test_preds)} ({np.mean(test_preds)*100:.1f}%)\")\n",
    "print(f\"Non-soil predictions: {len(test_preds) - np.sum(test_preds)} ({(1 - np.mean(test_preds))*100:.1f}%)\")\n",
    "\n",
    "# Visualize reconstruction errors distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(train_errors, bins=50, alpha=0.7, color='blue', label='Train Errors')\n",
    "plt.axvline(best_threshold, color='red', linestyle='--', label='Best Threshold')\n",
    "plt.title('Training Reconstruction Errors')\n",
    "plt.xlabel('Mean Squared Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(val_errors, bins=50, alpha=0.7, color='green', label='Validation Errors')\n",
    "plt.axvline(best_threshold, color='red', linestyle='--', label='Best Threshold')\n",
    "plt.axvline(error_threshold_for_pseudo, color='orange', linestyle='--', label='Pseudo-labeling Threshold')\n",
    "plt.title('Validation Reconstruction Errors')\n",
    "plt.xlabel('Mean Squared Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(test_errors, bins=50, alpha=0.7, color='purple', label='Test Errors')\n",
    "plt.axvline(best_threshold, color='red', linestyle='--', label='Best Threshold')\n",
    "plt.title('Test Reconstruction Errors')\n",
    "plt.xlabel('Mean Squared Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show first few predictions\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(\"Image ID\\t\\tReconstruction Error\\tPrediction\")\n",
    "print(\"-\" * 55)\n",
    "for i in range(10):\n",
    "    pred_label = \"Soil\" if test_preds[i] == 1 else \"Non-Soil\"\n",
    "    print(f\"{test_ids.iloc[i]['image_id']}\\t{test_errors[i]:.6f}\\t\\t{pred_label}\")\n",
    "\n",
    "print(\"\\nInference completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
